{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Experiments\n",
    "\n",
    "Test which features actually predict future price direction.\n",
    "\n",
    "**Key insight from r/algotrading**: Indicators (RSI, MAs, BBs, Donchian, Keltner) all do the same thing â€” they use the past to make a statement about the present. Don't obsess over which ones; obsess over whether they predict anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "from utils.features import compute_features, forward_return_direction\n",
    "from utils.data_loaders import load_yahoo\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download diverse sector stocks\n",
    "tickers = ['AAPL', 'MSFT', 'JPM', 'JNJ', 'XOM', 'AMZN', 'NVDA', 'KO', 'CAT', 'META']\n",
    "df = load_yahoo(tickers, start='2019-01-01', end='2024-12-31')\n",
    "print(f'Loaded: {len(df)} rows, {df[\"ticker\"].nunique()} tickers')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features per ticker\n",
    "featured_dfs = []\n",
    "for ticker, group in df.groupby('ticker'):\n",
    "    group = group.sort_values('date').reset_index(drop=True)\n",
    "    featured = compute_features(group)\n",
    "    featured['ticker'] = ticker\n",
    "    # Add target\n",
    "    featured['target'] = forward_return_direction(featured['close'], periods=5)  # 5-day direction\n",
    "    featured_dfs.append(featured)\n",
    "\n",
    "featured_df = pd.concat(featured_dfs, ignore_index=True).dropna()\n",
    "print(f'Feature matrix: {featured_df.shape}')\n",
    "print(f'Target distribution: {featured_df[\"target\"].value_counts().to_dict()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature-Target Correlation\n",
    "\n",
    "Which features actually correlate with future direction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['date', 'ticker', 'target', 'open', 'high', 'low', 'close', 'volume', 'adj_close']\n",
    "feature_cols = [c for c in featured_df.columns if c not in exclude]\n",
    "\n",
    "# Correlation with target\n",
    "correlations = featured_df[feature_cols + ['target']].corr()['target'].drop('target').sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "correlations.plot(kind='barh', ax=ax)\n",
    "ax.set_title('Feature Correlation with 5-day Forward Direction')\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nTop positive correlations:')\n",
    "print(correlations.tail(10))\n",
    "print('\\nTop negative correlations:')\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Predictive Power (LightGBM Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import lightgbm as lgb\n",
    "\n",
    "X = featured_df[feature_cols].values\n",
    "y = featured_df['target'].values\n",
    "\n",
    "# Train a quick model to get feature importance\n",
    "model = lgb.LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.05, verbose=-1)\n",
    "model.fit(X, y)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "importance.head(20).plot(x='feature', y='importance', kind='barh', ax=ax)\n",
    "ax.set_title('Top 20 Feature Importances (LightGBM gain)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Takeaways\n",
    "\n",
    "Fill in after running:\n",
    "- Which features have predictive power?\n",
    "- Are momentum features (returns) more useful than level features (RSI, MACD)?\n",
    "- Do cross-stock features add value?\n",
    "- How stable is feature importance across time?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
